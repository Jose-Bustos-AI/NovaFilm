FelicitaciÃ³n

Crack: ya tenemos vÃ­deos generados end-to-end con Kie.ai, DB Neon estable, logs finos y galerÃ­a funcionando. Ahora vamos a convertir el chat en un agente de prompt-engineering en espaÃ±ol sin romper nada de lo que ya funciona.

ğŸ§© Contexto

Queremos que el asistente hable siempre en espaÃ±ol, haga 3â€“4 preguntas cortas y encadenadas para afinar la idea (tipo de coche/estilo/ambiente/hora, etc.), y cuando tenga todo, construya un prompt final en inglÃ©s (obligatorio para Kie) y dispare la generaciÃ³n. El usuario debe ver un mensaje tipo: â€œPerfecto, dame unos minutillosâ€¦â€.

ğŸ§± Regla de oro

No cambies nada que ya funciona (auth, DB, endpoints, polling/callback, seeds y estados). LimÃ­tate a aÃ±adir el flujo conversacional y la orquestaciÃ³n para que, al finalizar las preguntas, se llame a la misma ruta de creaciÃ³n de job con el prompt en inglÃ©s.

ğŸ› ï¸ Instrucciones

System Prompt del agente (OpenAI) â€“ espaÃ±ol + multi-turno

En server/services/openai.ts (o donde definas el prompt del asistente), reemplaza/aÃ±ade un system prompt asÃ­ (respeta JSON final y que el chat visible sea en espaÃ±ol):

Eres un asistente conversacional que habla SIEMPRE en espaÃ±ol. Ayudas al usuario a crear un prompt Ã³ptimo para generar un video con IA (Kie.ai, modelo veo3_fast, 9:16).

Flujo:
1) El usuario da una idea inicial.
2) Haz EXACTAMENTE 3 o 4 preguntas cortas, una a la vez, para concretar (elige entre: tipo de sujeto/estilo visual/ambiente/hora/Ã©poca/pÃºblico/ritmo). Pregunta -> espera respuesta -> siguiente. Evita pÃ¡rrafos largos.
3) Cuando tengas suficiente info, responde:
   â€œPerfecto, ya tengo todo. Estoy preparando tu vÃ­deo. Dame unos minutillos ğŸš€.â€
4) A CONTINUACIÃ“N (misma respuesta) genera SOLO un bloque JSON vÃ¡lido con ESTA forma:
   {
     "finalPromptEnglish": "<prompt_de_video_en_INGLÃ‰S_bien_detallado_y_cinematogrÃ¡fico>"
   }
Reglas:
- Todo el chat visible es en espaÃ±ol.
- El JSON debe estar en INGLÃ‰S y ser vÃ¡lido (una sola lÃ­nea si es posible).
- No incluyas cÃ³digo ni explicaciones fuera del chat y del JSON final.
- No uses markdown en el JSON.


Estado conversacional en el frontend (Chat) â€“ â€œrefine flowâ€

En client/src/components/chat-interface.tsx introduce un modo de refinamiento:

mode: 'idle' | 'refining' | 'ready'

Al primer mensaje del usuario â†’ mode='refining'. Muestra preguntas del asistente y recoge respuestas.

Detecta el JSON final (clave finalPromptEnglish) en la Ãºltima respuesta del asistente:

Extrae el JSON con parser tolerante.

const finalPrompt = data.finalPromptEnglish;

Cambia a mode='ready' y lanza el flujo actual de generaciÃ³n usando /api/create-job con:

prompt = finalPrompt

model = 'veo3_fast'

aspectRatio = '9:16'

En el chat imprime: â€œPerfecto, ya tengo todo. Estoy preparando tu vÃ­deo. Dame unos minutillos ğŸš€.â€

Tras disparar, vuelve a mode='idle'.

No rompas el flujo actual: reutiliza la misma mutaciÃ³n que ya usa el chat para llamar a /api/refine-prompt y a /api/create-job. Solo aÃ±ade la detecciÃ³n del JSON final y la transiciÃ³n de estado.

Parser robusto del JSON final

En el cliente, aÃ±ade una funciÃ³n segura para extraer el objeto { finalPromptEnglish } de la Ãºltima respuesta del asistente:

Busca el primer { y el Ãºltimo } y haz JSON.parse con try/catch.

Si falla, sigue en modo preguntas y muestra: â€œNecesito una confirmaciÃ³n mÃ¡s para cerrar el prompt.â€

MensajerÃ­a y UX

Todas las preguntas y respuestas del asistente en espaÃ±ol y breves.

Cuando se dispare la generaciÃ³n, muestra el ETA actual: â€œSuele tardar 2â€“5 minutos. Te aviso en cuanto estÃ© listo.â€

MantÃ©n el scroll/overflow ya corregidos.

Back-end de refinamiento (si aplica)

Si existe endpoint /api/refine-prompt, actualÃ­zalo para pasar el nuevo system prompt y devolver Ã­ntegramente el texto del asistente (el frontend se encarga de extraer el JSON).

No cambies /api/create-job ni la validaciÃ³n/semillas/polling.

Salvaguardas

Timeout de refinamiento: si el usuario no responde en 90s, sugerir: â€œÂ¿Seguimos? Puedo generar con lo que tengo.â€

BotÃ³n â€œUsar lo que hayâ€: permite saltar preguntas y generar con la info parcial (el asistente rellena con defaults cinematogrÃ¡ficos).

âœ… Criterios de aceptaciÃ³n

El asistente siempre escribe en espaÃ±ol y hace 3â€“4 preguntas cortas antes de generar.

La Ãºltima respuesta del asistente contiene el mensaje en espaÃ±ol + un JSON vÃ¡lido con finalPromptEnglish en inglÃ©s.

El frontend detecta el JSON, dispara /api/create-job con el prompt en inglÃ©s y muestra el ETA.

No se rompe nada existente: seeds vÃ¡lidos, veo3_fast, 9:16, polling/callback, galerÃ­a y descargas siguen funcionando.